---
title: 'Presenting AI Fairness at Ignite Talks MSU'
date: 2024-11-1
permalink: /posts/2024/11/blog-post-1/
tags:
  - Ignite Talks
  - MSU
  - Talk
---

![Ignite Talks MSU Presentation Picture](/images/54107689053_1b11b59529_o.jpg)

I recently had the exciting opportunity to present at the Ignite Talks MSU, organized by the Michigan State University Museum. My presentation was titled *"Let's Teach ChatGPT Stereotypes to Make It Less Biased,"* and it explored the complex relationship between AI and bias. Ignite Talks feature a unique and fast-paced format: presenters have just five minutes to share their ideas, using 20 slides that automatically advance every 15 seconds. 

Originating in San Francisco in 2006, Ignite Talks has become a global phenomenon, occurring in over 350 cities across six continents. Ignite Talks at MSU is the only chapter in Michigan, and I was honored to be selected as a speaker. My goal was to inspire connection and deliver an engaging, informative experience for the audience.

Ignite Talks events are open to the public, making my recent presentation a unique opportunity.  While I have previously discussed AI fairness with fellow researchers at academic conferences, this was my first time addressing the topic with a general audience.  Knowing this presentation was open to everyone, my primary goal was to connect with attendees and deliver an engaging and informative experience, sparking their interest in and understanding of this important issue.

The intermission following my Ignite Talk provided a wonderful opportunity to connect with a diverse audience. I spoke with a range of attendees, from a high school teacher to an undergraduate researcher, and everyone I encountered expressed intrigue and a desire to learn more about AI fairness.  For me as a researcher, this was an invaluable experience.  It allowed me to directly inform the public about my research and, perhaps even more rewarding, I received positive feedback from those who attended, confirming that the message resonated with them.